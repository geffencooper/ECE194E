{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and set up random number generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "seed = 23\n",
    "rng = default_rng(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Description: This function takes a string of text and turns it into a list where\n",
    "             each element represents  a single text 'token' including punctuation\n",
    "             (These are the states of the markov chain). If desired, we can also\n",
    "             split the text into multitoken elements so that we can consider a\n",
    "             history of tokens (this breaks the markov property but is interesting\n",
    "             to explore). \n",
    "\n",
    "Input: text - A string of text\n",
    "       history_size - the number of tokens per element.\n",
    "\n",
    "Returns: - A list of individual tokens elements in chronological order,\n",
    "         - A list of all the multitoken elements in chronological order\n",
    "           (None if history size is 1).\n",
    "'''\n",
    "\n",
    "def text_to_list(text,history_size=1):\n",
    "    # insert spaces so we can use the split function while keeping punctuation\n",
    "    text = text.replace(\".\",\" . \").replace(\"!\",\" ! \").replace(\"?\",\" ? \").replace(\", \",\" , \")\\\n",
    "               .replace(\"; \",\" ; \").replace(\": \",\" : \").replace(\"\\\"\",\"\").replace(\".\\n\",\" . <NL> \")\\\n",
    "               .replace(\"!\\n\",\" . <NL> \").replace(\"?\\n\",\" . <NL> \")\n",
    "\n",
    "    # replace special characters with tokens\n",
    "    text = text.replace(\"\\t\", \" <TAB>\").replace(\"\\n\", \" <NL> \")\n",
    "\n",
    "    # save the end tokens\n",
    "    end_tokens = [\".\", \"?\", \"!\"]\n",
    "\n",
    "    # now split the text using a space as the delimeter\n",
    "    text_list = text.split()\n",
    "\n",
    "    # if each token is a state then we are done\n",
    "    if history_size == 1:\n",
    "        return text_list, None\n",
    "\n",
    "    # for multitoken states, combine items in the list\n",
    "    multitoken_items = []\n",
    "    idx = 0\n",
    "    while idx < len(text_list):\n",
    "        # handle ending punctuation to avoid cases where not at end (e.g. [' . It was'])\n",
    "        if idx+history_size-1 >= len(text_list):\n",
    "            break\n",
    "        if text_list[idx+history_size-1] in end_tokens:\n",
    "            multitoken_items.append(' '.join(text_list[idx:idx+history_size]))\n",
    "            idx = idx+history_size\n",
    "            continue\n",
    "\n",
    "        # combine items based on state size\n",
    "        multitoken_items.append(' '.join(text_list[idx:idx+history_size]))\n",
    "        idx += 1\n",
    "\n",
    "    return text_list, multitoken_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['My', 'name', 'is', 'Geffen', 'Cooper', '.', 'What', 'is', 'yours', '?'],\n",
       " ['My name',\n",
       "  'name is',\n",
       "  'is Geffen',\n",
       "  'Geffen Cooper',\n",
       "  'Cooper .',\n",
       "  'What is',\n",
       "  'is yours',\n",
       "  'yours ?'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"My name is Geffen Cooper. What is yours?\"\n",
    "text_to_list(text,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Description: This function takes the ordered text list and creates\n",
    "             a markov chain representation from it. Each token represents a state \n",
    "             and the token immediately following represents a potential\n",
    "             next state. We can represent this as a nested dictionary where at\n",
    "             the first level we have all the unique words in the corpus (i.e. the states)\n",
    "             and at the second level we have all the potential next states and\n",
    "             their relative probability of following.\n",
    "             \n",
    "             When the history size is greater than one, we will use multiple words to \n",
    "             determine the next word. This technically breaks the markov property but\n",
    "             will enable more realistic text by considering the history of words instead\n",
    "             of only the current one.\n",
    "\n",
    "Input: token_list - An ordered list of individual text tokens.\n",
    "       history_size - Number of past tokens to consider\n",
    "       multitoken_list - List of multitoken elements for history_size > 1\n",
    "\n",
    "Returns: A nested dictionary representing the Markov Chain.\n",
    "'''\n",
    "def gen_word_dist(token_list, history_size=1,multitoken_list=None):\n",
    "    # create the first level from the unique tokens (all the states)\n",
    "    unique_tokens = set(token_list)\n",
    "    text_dict = dict.fromkeys(unique_tokens)\n",
    "\n",
    "    # create a nested dictionary for each unique token (all the outgoing states)\n",
    "    for token in text_dict.keys():\n",
    "        text_dict[token] = {}\n",
    "    \n",
    "    # now add the words that follow each unique token\n",
    "    # where the key is the following word and the value is the count\n",
    "    for idx,token in enumerate(token_list[1:]):\n",
    "        try: # try to increment the count of the token\n",
    "            text_dict[token_list[idx]][token] += 1\n",
    "        except KeyError: # otherwise set it as the first occurence\n",
    "            text_dict[token_list[idx]][token] = 1\n",
    "\n",
    "    # now we convert the counts to probabilities\n",
    "    for state in text_dict.keys():\n",
    "        total = sum(text_dict[state].values())\n",
    "        for out_state in text_dict[state].keys():\n",
    "            text_dict[state][out_state] = text_dict[state][out_state]/total\n",
    "            \n",
    "    return text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Description: This function will take a given state in the markov chain and\n",
    "             select the next state probabilistically.\n",
    "\n",
    "Input: The current state as a dictionary.\n",
    "\n",
    "Returns: The next state.\n",
    "'''\n",
    "\n",
    "def get_next_state(current_state):\n",
    "    out_states = list(current_state.keys())\n",
    "    probs = list(current_state.values())\n",
    "    \n",
    "    probs[0] += 1-sum(probs)\n",
    "    return rng.choice(a=out_states,size=1,p=probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Description: This function will step through the generated markov chain\n",
    "             to produce sentences based on the input parameters. It will\n",
    "             format the text as well.\n",
    "\n",
    "Input: The first word (must be in the corpus), the number of desired sentences,\n",
    "       the markov chain dictionary\n",
    "\n",
    "Returns: The formatted output text.\n",
    "'''\n",
    "\n",
    "def generate_text(first_word,num_sentences,markov_chain):\n",
    "    # get the state from the desired first word\n",
    "    curr_state = markov_chain[first_word]\n",
    "\n",
    "    # start the text sequence\n",
    "    text = [first_word]\n",
    "\n",
    "    sentence_count = 0\n",
    "    # keep adding words until we reach the sentence count\n",
    "    while sentence_count < num_sentences:\n",
    "        # get the next word\n",
    "        next_state = get_next_state(curr_state)\n",
    "\n",
    "        # add this word to the text sequence (only get the string)\n",
    "        text.append(next_state.tolist()[0])\n",
    "\n",
    "        # set the current state to the next state (only get the string)\n",
    "        curr_state = markov_chain[next_state[0]]\n",
    "\n",
    "        # check if the sentence ended\n",
    "        if next_state[0] == '.' or next_state[0] == '?' or next_state[0] == '!':\n",
    "            sentence_count += 1\n",
    "\n",
    "    # format the text sequence into a sentence\n",
    "    text_string = \" \".join(text)\n",
    "    text_string = text_string.replace(\" . \",\". \").replace(\" , \",\", \").replace(\" ; \",\"; \").replace(\" ! \",\"! \").replace(\" ? \",\"? \").replace(\" : \",\": \")\n",
    "    text_string = text_string.replace(\"<TAB> \",\"\\t\").replace(\"<NL> \",\"\\n\")\n",
    "    text_string_final = text_string[:-2]+text_string[-1]\n",
    "    return text_string_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi all, \n",
      "Hi all, \n",
      "Hi all, \n",
      "Best, \n",
      "\n",
      "\n",
      "Hi all, \n",
      "I think it would be good to extend the office is going to answer questions over zoom since my office hour on Monday: 1) implementing ML algorithm(s) learned in the midterm exam. The final project report.\n"
     ]
    }
   ],
   "source": [
    "with open('1789-04-30-first-inaugural-address.txt',encoding='utf-8') as f:\n",
    "    contents = f.read()\n",
    "\n",
    "with open('2017-01-20-inaugural-address.txt',encoding='utf-8') as f:\n",
    "    contents = f.read()\n",
    "\n",
    "with open('email.txt',encoding='utf-8') as f:\n",
    "    contents = f.read()\n",
    "\n",
    "d = gen_word_dist(text_to_list(contents))\n",
    "print(generate_text(\"Hi\",2,d))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12fed321ce14db8c70d5fd7d87816765955c1efc0c914b111c5a8918a271e9da"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
